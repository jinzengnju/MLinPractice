# 模型保存

在迁移学习以及模型finetune的过程中，经常涉及到模型的存储与加载，今天就模型保存以及加载简单介绍一下。

## 检查点

手动建立检查点文件以及手动存储，使用tf.train.Checkpoint与tf.train.CheckpointManager

~~~python
ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)
manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)
def train_and_checkpoint(net, manager):
  ckpt.restore(manager.latest_checkpoint)
  if manager.latest_checkpoint:
    print("Restored from {}".format(manager.latest_checkpoint))
  else:
    print("Initializing from scratch.")

  for _ in range(50):
    example = next(iterator)
    loss = train_step(net, example, opt)
    ckpt.step.assign_add(1)
    if int(ckpt.step) % 10 == 0:
      save_path = manager.save()
      print("Saved checkpoint for step {}: {}".format(int(ckpt.step), save_path))
      print("loss {:1.2f}".format(loss.numpy()))
~~~

观察checkpoint检查点中的所有变量以及shape

~~~python
reader = tf.train.load_checkpoint('./tf_ckpts/')
shape_from_key = reader.get_variable_to_shape_map()
dtype_from_key = reader.get_variable_to_dtype_map()

sorted(shape_from_key.keys())

key = 'net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE'

print("Shape:", shape_from_key[key])
print("Dtype:", dtype_from_key[key].name)

#Shape: [1, 5]
#Dtype: float32
~~~



## SavedModel

法一：查看savedmodel文件中的变量(tf2.0方法)

~~~python
# -*- coding:UTF-8 -*-

import tensorflow as tf

with tf.Session() as sess:
    loaded=tf.saved_model.load(export_dir="/home/jin/pythonPro/export_model")
    for v in loaded.variables:
        print(v.name)
~~~

法二：tf.saved_model.loader.load方法（tf114）

需要注意的是，这里的tag [tf.compat.v1.saved_model.tag_constants.SERVING]需要与保存savedmodel时的tag一致。

~~~python
tf.saved_model.loader.load(sess,[tf.compat.v1.saved_model.tag_constants.SERVING],"/home/jin/pythonPro//export_model")
graph = tf.get_default_graph()
[print(n.name) for n in tf.get_default_graph().as_graph_def().node]
~~~

得到他们名字之后，就可以根据名字获取出对应tensor

~~~python
x = sess.graph.get_tensor_by_name("input_example_tensor:0")
    y = sess.graph.get_tensor_by_name('hash_table:0')
    print(sess.run(y, feed_dict={x: [example1.SerializeToString()]}))
~~~

使用保存的savedmodel文件进行预测代码，**可以快速验证savedmodel是否可以执行**（非grpc的请求方法）

~~~
import tensorflow as tf
def _bytes_feature(value):
    if not isinstance(value, list):
        value = [value]
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))

example1 = tf.train.Example(features=tf.train.Features(feature={
          'gid': _bytes_feature("135415".encode()),
          'cid1': _bytes_feature("11".encode()),
          'cid2': _bytes_feature("11".encode()),
          'cid3': _bytes_feature("2860".encode()),
          'brand': _bytes_feature("11".encode()),
          'merchant': _bytes_feature("11".encode())
      }))


loaded=tf.saved_model.load("/home/jin/pythonPro/Bert4Rec/export_model")
f = loaded.signatures["serving_default"]
print(f(tf.constant([example1.SerializeToString()])))
~~~

## 从savedmodel中恢复并进行finetune（tf2.0）

### Basic fine-tuning

导入模型后直接使用concrete function

~~~python
imported = tf.saved_model.load(module_no_signatures_path)
optimizer = tf.optimizers.SGD(0.05)

def train_step():
  with tf.GradientTape() as tape:
    loss = (10. - imported(tf.constant(2.))) ** 2
  variables = tape.watched_variables()
  grads = tape.gradient(loss, variables)
  optimizer.apply_gradients(zip(grads, variables))
  return loss
~~~

### General fine-tuning

需要注意的是：finetune期间Next to the `__call__` attribute, there are `.variable` and `.trainable_variable` attributes with the corresponding lists of variables. A variable that was originally trainable but is meant to be frozen during fine-tuning is omitted from `.trainable_variables`

~~~python
loaded = tf.saved_model.load(mobilenet_save_path)
print("MobileNet has {} trainable variables: {}, ...".format(
          len(loaded.trainable_variables),
          ", ".join([v.name for v in loaded.trainable_variables[:5]])))
    
trainable_variable_ids = {id(v) for v in loaded.trainable_variables}
non_trainable_variables = [v for v in loaded.variables
                           if id(v) not in trainable_variable_ids]
print("MobileNet also has {} non-trainable variables: {}, ...".format(
          len(non_trainable_variables),
          ", ".join([v.name for v in non_trainable_variables[:3]])))

~~~

### 获取graph中的所有tensor、变量、op以及节点方法

* all nodes

  ~~~
  all_nodes = [n for n in tf.get_default_graph().as_graph_def().node]
  ~~~

* all ops

  对于op，使用value将可以获取对应的tensor

  ~~~python
  for op in tf.get_default_graph().get_operations():
      print(str(op.name))
      
      
  #graph = tf.get_default_graph()    
  #tensors_per_node = [node.values() for node in graph.get_operations()]
  #tensor_names = [tensor.name for tensors in tensors_per_node for tensor in tensors]
  ~~~

* all variables

  ~~~
  for op in tf.global_variables():
  	print(str(op.name))
  ~~~

* all tensors

  ~~~
  all_tensors = [tensor for op in tf.get_default_graph().get_operations() for tensor in op.values()]
  
  #print(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))
  ~~~

  以上是在tensorflow1.X的版本用法，如果是在tf2.0中，获取默认图的时候，应该使用graph = func.get_concrete_function().graph


# Tensorflow性能分析

### 使用timeline分析tensorflow模型

[参考链接](https://www.tensorflow.org/guide/profiler)

### 显存占满，GPU利用率比较低，且频繁变化

- 情况1

之前参加腾讯广告算法比赛的时候，遇到这样一个问题：GPU显存占满，**但是GPU利用率比较低，而且不稳定**。分析其原因如下：Embedding矩阵非常大，有\[200万, 128\]。这样一个非常大的矩阵是无法放在GPU上的，所以这个矩阵将会被放在CPU上。那么，就会造成：

对于每一个batch的数据，在CPU上执行完embedding操作后，将结果再传输给GPU运算，传输时间显然是不能忽略的。并且我们的模型并不是太复杂，只是一层的Transformer。所以，在CPU中的运算以及传输时间占据主要部分，而GPU运算一个相对比较简单的网络是很快的，所以呈现出上述结果。

当我们将Embedding矩阵强行改小，此时GPU利用率稳定达到70%。说明，embedding此时是在GPU中运算的，不需要再像以前那样将庞大的embedding结果传输到GPU，省去了传输耗时。

- 情况2

data pipline的性能极差，大部分时间消耗在预处理数据。建议使用tf.data API

[参考链接](https://zhuanlan.zhihu.com/p/53345706)

### GPU内存占用的问题

往往由模型的大小，以及batchsize影响。GPU的内存占用率主要是模型的大小，其次是batch size的大小，也会占用影响内存占用率。batch size设置为128，与设置为256相比，内存占用率是接近于2倍关系。所以在模型结构固定的情况下，尽量将batch size设置大，充分利用GPU的内存。

### tf.data+estimator如何方便的进行debug

estimator高阶API已经不具有session.run方法了，所以无法打印出tensor对应的值。不过可以在计算图中插入tf.Print进行Tensor的查看。如果是其他需要周期性打印的tensor，那么就用tf.train.LoggingTensorHook包装一下然后丢进estimator.train里吧
